{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2602fbb9",
   "metadata": {},
   "source": [
    "## GeoLatinas SPWLA 2021 Machine Learning solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8291c0ea",
   "metadata": {},
   "source": [
    "### Load libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977a9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import missingno as msno\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92bbbfc",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5692e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train dataset \n",
    "train_path = r\"./data/train.csv\"\n",
    "train_data = pd.read_csv(train_path)\n",
    "\n",
    "#load test dataset\n",
    "test_path = r\"./data/train.csv\"\n",
    "test_data = pd.read_csv(test_path)\n",
    "\n",
    "logs_discarded = [\"BS\", \"CALI\", \"DENC\", \"ROP\"]\n",
    "targets = ['PHIF', 'VSH', 'SW']\n",
    "\n",
    "#drop irrelevant columns\n",
    "train_data = train_data.drop(columns=logs_discarded)\n",
    "test_data =  test_data.drop(columns=logs_discarded)\n",
    "\n",
    "#convert -9999 values to NaN\n",
    "train_data = train_data.mask(train_data == -9999.0, np.nan)\n",
    "test_data = train_data.mask(test_data == -9999.0, np.nan)\n",
    "\n",
    "#drop row if nan in the target columns for train dataset\n",
    "train_data = train_data.dropna(subset=targets)\n",
    "\n",
    "#convert resistivity to log\n",
    "train_data[\"RDEP\"] = np.log10(train_data['RDEP'])\n",
    "train_data[\"RMED\"] = np.log10(train_data['RMED'])\n",
    "test_data[\"RDEP\"] = np.log10(train_data['RDEP'])\n",
    "test_data[\"RMED\"] = np.log10(train_data['RMED'])\n",
    "\n",
    "#interpolate missing values \n",
    "test_data=test_data.interpolate()\n",
    "train_data = train_data.interpolate()\n",
    "pef_mean = np.mean(train_data[\"PEF\"])\n",
    "train_data['PEF'] = train_data['PEF'].fillna(pef_mean)\n",
    "\n",
    "#separate features (x) and targets (y) on training data\n",
    "x_train = train_data.loc[:, features]\n",
    "y_train = train_data.loc[:, targets]\n",
    "\n",
    "#Normalize data\n",
    "sc = StandardScaler()\n",
    "x_train = pd.DataFrame(sc.fit_transform(x_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
